{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Wrangling Template\n",
    "\n",
    "---\n",
    "\n",
    "*Use uma abordagem iterativa, comece fazendo todas as etapas, pequeno. Depois vá aumentando e sofisticando!*\n",
    "\n",
    "- Gather\n",
    "\n",
    "- Assess\n",
    "\n",
    "- Clean\n",
    "\n",
    "E...\n",
    "\n",
    "- Analyse + Visualize + Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Gather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with zipfile.ZipFile('armenian-online-job-postings.zip', 'r') as myzip:\n",
    "    myzip.extractall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read CSV (comma-separated) file into DataFrame\n",
    "df = pd.read_csv('online-job-postings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- duração (vários formatos)\n",
    "\n",
    "- deadline (vários formatos)\n",
    "\n",
    "- ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Term.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hadley Wickam\n",
    "\n",
    "- Às vezes, deixe o preciosismo acadêmico de lado. Nem sempre o jeito mais **elegante** do dado o ajuda a resolver seu problema **prático**!\n",
    "\n",
    "Pense antes em:\n",
    "\n",
    "- **agilidade** (optimalidade - é rápido, eficiente)\n",
    "\n",
    "- **funcionalidade** (as coisas estão à mão)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The high-level **gathering** process:\n",
    "\n",
    "obtaining data (downloading a file from the internet, scraping a web page, querying an API, etc.)\n",
    "importing that data into your programming environment (e.g. Jupyter Notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_limpo = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uma maneira alternativa de renomear colunas usando dicionário (não é necessário renomear todas!):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_limpo = df_limpo.rename(columns={'ApplicationP': 'ApplicationProcedure', \n",
    "                                    'AboutC': 'AboutCompany',\n",
    "                                    'RequiredQual': 'RequiredQualifications',\n",
    "                                    'JobRequirment': 'JobRequirements'})\n",
    "df_limpo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Assess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Problemas de qualidade:\n",
    "\n",
    "- data quality - **dirty** data\n",
    "\n",
    "Problemas de estrutura:\n",
    "\n",
    "- data tidiness - **messy** data [aqui](https://cran.r-project.org/web/packages/tidyr/vignettes/tidy-data.html)\n",
    "\n",
    "---\n",
    "\n",
    "- **missing** data\n",
    "\n",
    "- **invalid** data\n",
    "\n",
    "- **inaccurate** data\n",
    "\n",
    "- **inconsistent** data\n",
    "\n",
    "---\n",
    "\n",
    "Data quality is a perception or an assessment of data's fitness to serve its purpose in a given context. \n",
    "\n",
    "---\n",
    "\n",
    "Two ways of assess data:\n",
    "\n",
    "- **visually**\n",
    "\n",
    "- **programmatic**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df_clean.rename(columns={'ApplicationP': 'ApplicationProcedure',\n",
    "                                    'AboutC': 'AboutCompany',\n",
    "                                    'RequiredQual': 'RequiredQualifications',\n",
    "                                    'JobRequirment': 'JobRequirements'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asap_list = ['Immediately', 'As soon as possible', 'Upon hiring',\n",
    "             'Immediate', 'Immediate employment', 'As soon as possible.', 'Immediate job opportunity',\n",
    "             '\"Immediate employment, after passing the interview.\"',\n",
    "             'ASAP preferred', 'Employment contract signature date',\n",
    "             'Immediate employment opportunity', 'Immidiately', 'ASA',\n",
    "             'Asap', '\"The position is open immediately but has a flexible start date depending on the candidates earliest availability.\"',\n",
    "             'Immediately upon agreement', '20 November 2014 or ASAP',\n",
    "             'immediately', 'Immediatelly',\n",
    "             '\"Immediately upon selection or no later than November 15, 2009.\"',\n",
    "             'Immediate job opening', 'Immediate hiring', 'Upon selection',\n",
    "             'As soon as practical', 'Immadiate', 'As soon as posible',\n",
    "             'Immediately with 2 months probation period',\n",
    "             '12 November 2012 or ASAP', 'Immediate employment after passing the interview',\n",
    "             'Immediately/ upon agreement', '01 September 2014 or ASAP',\n",
    "             'Immediately or as per agreement', 'as soon as possible',\n",
    "             'As soon as Possible', 'in the nearest future', 'immediate',\n",
    "             '01 April 2014 or ASAP', 'Immidiatly', 'Urgent',\n",
    "             'Immediate or earliest possible', 'Immediate hire',\n",
    "             'Earliest  possible', 'ASAP with 3 months probation period.',\n",
    "             'Immediate employment opportunity.', 'Immediate employment.',\n",
    "             'Immidietly', 'Imminent', 'September 2014 or ASAP', 'Imediately']\n",
    "\n",
    "for palavra in asap_list:\n",
    "    df_clean.StartDate.replace(palavra , 'ASAP' , inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizar uma amostra aleatória:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Através de codificação:\n",
    "    \n",
    "    .head (DataFrame and Series)\n",
    "\n",
    "    .tail (DataFrame and Series)\n",
    "\n",
    "    .sample (DataFrame and Series)\n",
    "\n",
    "    .info (DataFrame only)\n",
    "\n",
    "    .describe (DataFrame and Series)\n",
    "\n",
    "    .value_counts (Series only)\n",
    "\n",
    "Various methods of indexing and selecting data (.loc and bracket notation with/without boolean indexing, also .iloc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contagem dos tipos de reações adversas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adverse_reactions.adverse_reaction.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quantos pacientes vieram da cidade de Nova Iorque:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(patients.loc[patients['city'] == 'New York'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Soluções para qualidade\n",
    "\n",
    "- campos vazios (NaN) devem ser identificados e tratados conforme o caso\n",
    "\n",
    "- CEP e outros similares devem strings numéricas (e não números)\n",
    "\n",
    "- máscaras em strings numéricas devem ser interpretadas e removidas\n",
    "\n",
    "- Estado e Município são campos de categoria (e não strings de texto) e devem ser agrupados e padronizados\n",
    "\n",
    "- campos com dados misturados, como endereços devem ser interpretados e quebrados em vários campos\n",
    "\n",
    "- valores discrepantes devem ser descobertos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patients.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entre colchetes encontra-se a cláusula de filtragem:\n",
    "\n",
    "    patients['address'].isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patients[patients['address'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patients.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como endereço é uma coisa complexa, quando dois aparecem duplicados, é quase certo que todo o registro está assim:\n",
    "\n",
    "*o .counts() funciona um pouco como um histograma* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patients.address.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Daí eu listo os duplicados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patients[patients.address.duplicated()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eu posso testar hipóteses para erros por exemplo, em um peso muito abaixo do possível:\n",
    "\n",
    "*será que este peso não está representado em Kilogramas?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patients.weight.sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_lbs = patients[patients.surname == 'zaitseva'].weight * 2.20462\n",
    "weight_in = patients[patients.surname == 'zaitseva'].height\n",
    "bmi_check = 703 * weight_lbs / (height_in * height_in)\n",
    "bmi_check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patients[patients.surname = 'zaitseva'].bmi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe que há muitos registros de fato em branco, mas preenchidos com apenas um \"-\". Isso falsifica a busca por nulos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(treatments.novodra.isnull())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O desvio padrão ira considerar estes campos com \"-\" como com valor ZERO. Isso modifica a curva dos nossos dados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STDEVA()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Soluções para desordem [aqui](https://cran.r-project.org/web/packages/tidyr/vignettes/tidy-data.html)\n",
    "\n",
    "A ideia básica é que os dados se encaixem na forma 1-normal:\n",
    "\n",
    "- linhas\n",
    "\n",
    "- colunas\n",
    "\n",
    "- tabela completa\n",
    "\n",
    "Problemas comuns são:\n",
    "\n",
    "- **coluna** com mais de um tipo de dado (como endereço e e-mail) e que deve ser dividida pela função .split(), interpretando o separador, em **várias colunas**\n",
    "\n",
    "- **coluna** que representa uma lista de dados (maçã, banana, alface, alfavaca) e que devem ser interpretados e transformados em **lista**, ou subtabela com relacionamento 1:n\n",
    "\n",
    "- às vezes colunas diferentes apresentam **dados excludentes**, o que é um erro conceitual. Isso gera muitos espaços vazios em um dataset. O ideal é unir os dados com a função .melt() e criar uma outra coluna definindo qual o tipo de dado que está sendo representado\n",
    "\n",
    "- **tabela** que contém mais de uma família de dados (como dados do paciente e do tratamento). Ela deve ser dividida em mais de uma **tabela**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como os dados deterioram:\n",
    "\n",
    "- We're going to have user entry errors\n",
    "\n",
    "- In some situations, we won't have any data coding standards, or where we do have standards they'll be poorly applied, causing problems in the resulting data\n",
    "\n",
    "- We might have to integrate data where different schemas have been used for the same type of item\n",
    "\n",
    "- We'll have legacy data systems, where data wasn't coded when disc and memory constraints were much more restrictive than they are now. Over time systems evolve. Needs change, and data changes\n",
    "\n",
    "- Some of our data won't have the unique identifiers it should\n",
    "\n",
    "- Other data will be lost in transformation from one format to another\n",
    "\n",
    "- And then, of course, there's always programmer error\n",
    "\n",
    "- And finally, data might have been corrupted in transmission or storage by cosmic rays or other physical phenomenon. So hey, one that's not our fault"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Clean\n",
    "\n",
    "É um processo **iterativo** (e não preciso fazer tudo de uma vez!)\n",
    "\n",
    "#### Define\n",
    "\n",
    "- quero cabeçalhos melhores\n",
    "\n",
    "- quero coisas parecidas organizadas dentro de um mesmo tipo\n",
    "\n",
    "#### Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Type of cleaning: **programmatic**\n",
    "\n",
    "- **Define**: convert our assessments into defined cleaning tasks. These definitions also serve as an instruction list so others (or yourself in the future) can look at your work and reproduce it.\n",
    "\n",
    "- **Code**: convert those definitions to code and run that code.\n",
    "\n",
    "- **Test**: test your dataset, visually or with code, to make sure your cleaning operations worked.\n",
    "    \n",
    "*Always make copies of the original pieces of data before cleaning!*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Estratégia de limpeza\n",
    "\n",
    "- comece por dados ausentes (o mais difícil)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uma das formas de encontrar duplicatas é unir todas as tabelas com Pandas Series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_columns = pd.Series(list(patients) + list(treatments) + list(adverse_reactions))\n",
    "all_columns[all_columns.duplicated()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_limpo.StartDate.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Missão:** Concatene os dados ausentes, que se encontram em outro CSV\n",
    "\n",
    "*isso é uma espécie de Union*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "treatments_cut = pd.read_csv('treatments_cut.csv')\n",
    "treatments_clean = pd.concat([treatments_clean, treatments_cut],\n",
    "                             ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define, Code, Test\n",
    "\n",
    "**Missão:** Recalcule a coluna hba1c_change com hba1c_start - hba1c_end\n",
    "\n",
    "*agora isso é uma operação em massa em um dos campos - transformá-lo, linha a linha em uma conta*\n",
    "\n",
    "*observe que a sintaxe dos comandos no Pandas não favorece muito o entendimento - SQL é mais claro!*\n",
    "\n",
    "*observe que esta não é a melhor prática - não é necessário armazenar em uma estrutura de dados um dado derivado!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "treatments_clean.hba1c_change = (treatments_clean.hba1c_start - treatments_clean.hba1c_end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Missão:** Separe dados de telefone e de email em colunas diferentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patients_clean['phone_number'] = patients_clean.contact.str\n",
    "                                .extract('((?:\\+\\d{1,2}\\s)?\\(?\\d{3}\\)?[\\s.-]?\\d{3}[\\s.-]?\\d{4})', expand=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*[a-zA-Z] significa que todos os emails neste dataset iniciam e terminam com uma letra:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patients_clean['email'] = patients_clean.contact.str\n",
    "                         .extract('([a-zA-Z][a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+[a-zA-Z])', expand=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*axis=1 significa que estamos referindo uma coluna:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patients_clean = patients_clean.drop('contact', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expressões regulares - testador [aqui](https://rubular.com/r/UfIbUhPuP1)\n",
    "\n",
    "---\n",
    "\n",
    "#### Tutorial [aqui](https://www.datacamp.com/community/tutorials/python-regular-expression-tutorial?utm_source=adwords_ppc&utm_campaignid=1455363063&utm_adgroupid=65083631748&utm_device=c&utm_keyword=&utm_matchtype=b&utm_network=g&utm_adpostion=1t1&utm_creative=278443377092&utm_targetid=dsa-473406579035&utm_loc_interest_ms=&utm_loc_physical_ms=1001541&gclid=Cj0KCQiAhKviBRCNARIsAAGZ7CfK4RI5CCCSAzz89yFpON-IPO8AS2NOL0EaOrwqHhrYKm-kZjCHJTEaAv48EALw_wcB)\n",
    "\n",
    "dígito (0-9)\n",
    "\n",
    "caractere (a-z, A-Z, 0-9, _)\n",
    "\n",
    "espaço (space, tab, newline)\n",
    "\n",
    "1. Classes de caracteres\n",
    "\n",
    "\n",
    "        .           any character except newline\n",
    "\n",
    "        \\w \\d \\s\tword, digit, whitespace\n",
    "\n",
    "        \\W \\D \\S\tnot word, digit, whitespace\n",
    "\n",
    "        [abc]\t    any of a, b, or c\n",
    "\n",
    "        [^abc]\t    not a, b, or c\n",
    "        \n",
    "        [a-g]\t    character between a & g\n",
    "\n",
    "2. Âncoras\n",
    "\n",
    "        ^abc$       start / end of the string\n",
    "\n",
    "        \\b \\B\t    word, not-word boundary\n",
    "       \n",
    "3. Caracteres de Escape\n",
    "\n",
    "        \\. \\* \\\\\tescaped special characters\n",
    "\n",
    "        \\t \\n \\r\ttab, linefeed, carriage return\n",
    "\n",
    "4. Agrupamentos & Busca ao redor\n",
    "\n",
    "        (abc)\t    capture group\n",
    "\n",
    "        \\1\t        backreference to group #1\n",
    "        \n",
    "        (?:abc)\t    non-capturing group\n",
    "\n",
    "        (?=abc)\t    positive lookahead\n",
    "\n",
    "        (?!abc)\t    negative lookahead\n",
    "\n",
    "\n",
    "5. Quantificadores e alternância\n",
    "\n",
    "        a* a+ a?\t0 or more, 1 or more, 0 or 1\n",
    "\n",
    "        a{5} a{2,}\texactly five, two or more\n",
    "\n",
    "        a{1,3}\t    between one & three\n",
    "\n",
    "        a+?a{2,}?\tmatch as few as possible\n",
    "\n",
    "        ab|cd    \tmatch ab or cd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Video](https://www.youtube.com/watch?v=K8L6KVGG-7o) de tutorial, com o exemplo que segue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Isso é uma string bruta (raw string):\n",
    "\n",
    "*como ela não pega formatação, eu posso escrever nela o que eu quiser. Isso é muito importante na hora de jogar os parâmetros para o meu parser, sempre usar uma string bruta. Assim nenhum comando se perde no caminho!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\\\tTAB'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = r'\\tTAB'\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E isso é uma string formatada:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTAB\n"
     ]
    }
   ],
   "source": [
    "a = '\\tTAB'\n",
    "print (a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O método **.compile()** transforma padrões → variáveis\n",
    "\n",
    "A ideia por trás disso:\n",
    "\n",
    "- eu crio um parser personalizado, compilado através do método\n",
    "\n",
    " - os parâmetros do meu parser podem ser realmente complexos e entram naquela sequência de raw text (é quase como uma nova linguagem e funciona mais ou menos como naquelas antigas máquinas de fita perfurada, uma sequência de programação é inserida)\n",
    " \n",
    " - eu tenho comandos especiais\n",
    " \n",
    "                 . ^ $ * + ? {} [] () \\ |\n",
    " \n",
    " - pode parecer utra-complexo, mas eu começo com um padrão simples e depois vou elaborando. Com a prática, eu coloco sequências super complexas sem muita dificuldade. O que parece difícil é porque a linguagem de parsering é muito primária\n",
    " \n",
    "- depois eu posso chamar o padrão por exemplo no método **.finditer()**\n",
    "\n",
    " - ele simplesmente me grava as localizações do texto buscado em uma lista. A partir dessa lista, chamar o cortador de strings é facílimo e problema resolvido!\n",
    " \n",
    " - todos os módulos do Python foram feitos para conversar facilmente entre eles. Se você encontrou algo que parece relativamente simples e que está dando um trabalhão em programação, quase que certamente você está fazendo pelo caminho mais difícil!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O importante aqui é o que está dentro desta raw 'abc' é ela quem dá toda a inteligência ao processo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_sre.SRE_Match object; span=(16, 19), match='abc'>\n"
     ]
    }
   ],
   "source": [
    "sentenca = 'teste de coisas abcurdas 123 texto'\n",
    "padrao = re.compile(r'abc')\n",
    "encontrados = padrao.finditer(sentenca)\n",
    "\n",
    "for encontrado in encontrados:\n",
    "    print(encontrado)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metacaracteres precisam ser escapados (escaped):\n",
    "\n",
    "            . ^ $ * + ? { [ ( \\ |\n",
    "\n",
    "*insira o \\ antes deles! São também eles que dão toda a inteligência ao meu processo*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como eu começo o meu trabalho?\n",
    "\n",
    "Primeiro eu pego uma sequência que eu quero que meu sistema capture e misturo num arquivo com outras coisas. O fundamental é que ele consiga fazer o parser por exemplo, de números de telefone no meio de um texto absurdo. Suponha que meus telefones tenham o seguinte formato:\n",
    "\n",
    "            0800 942 4425\n",
    "            0900 342 4452\n",
    "            1119 341 4515\n",
    "            3315 331 1049\n",
    "            \n",
    "*há muitos métodos no re. Eles podem ser consultados [aqui](https://docs.python.org/3/library/re.html)*\n",
    "\n",
    "            .compile() compila meu argumento\n",
    "            .finditer() faz a iteração de busca\n",
    "            .findall() acha todos e joga numa tupla, mas sem detalhamento\n",
    "            .sub() substitui no documento o que foi encontrado (bom para gerar um documento corrigido)\n",
    "            .group() mostra apenas o grupo específico (group(0) é basicamente tudo o que foi capturado)\n",
    "            .span() localização geográfica do resultado\n",
    "            .match() correspondência exata\n",
    "            .search() devolve o primeiro encontrado que casa com a busca\n",
    "            \n",
    "*e flags úteis, que podem simplificar minha vida*\n",
    "\n",
    "            padrao = re.compile(r'teste', re.IGNORECASE) isso evita eu ter que buscar por todas as combinações de case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "posição: (16, 29) telefone: 0800 942 4425\n",
      "posição: (44, 57) telefone: 0900 342 4452\n",
      "posição: (72, 85) telefone: 1119 341 4515\n",
      "posição: (100, 113) telefone: 3315 331 1049\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "sentenca = \"\"\"teste de coisas 0800 942 4425\n",
    "              0900.342.4452\n",
    "              1119-341-4515\n",
    "              3315 331 1049\n",
    "              abcurdas 123 texto\"\"\"\n",
    "\n",
    "#padrao = re.compile(r'abc') -> funcionou o teste inicial, agora eu aprimoro\n",
    "#padrao = re.compile(r'\\d\\d\\d\\d.\\d\\d\\d.\\d\\d\\d\\d') #-> agora pegou todos os números, ótimo (o . pega qualquer objeto!)\n",
    "#padrao = re.compile(r'\\d{4}.\\d{3}.\\d{4}') #-> o uso de quantificador deixa o código mais elegante - e fácil de ser lido\n",
    "#padrao = re.compile(r'\\d{4}[.| |-]\\d{3}[.| |-]\\d{4}') #-> o colchetes denota apenas um caractere, o separador, de 3 tipos\n",
    "padrao = re.compile(r'(\\d{4})[.| |-](\\d{3})[.| |-](\\d{4})') #-> os parênteses geram 3 agrupamentos distintos, preciso deles\n",
    "encontrados = padrao.finditer(sentenca)\n",
    "\n",
    "for encontrado in encontrados:\n",
    "    #print(encontrado) ->isso é o resultado bruto, mas eu posso chamar pelos grupos!\n",
    "    print('posição: {} telefone: {} {} {}'.format(encontrado.span(),\n",
    "                                                  encontrado.group(1), encontrado.group(2), encontrado.group(3)))\n",
    "    #print(encontrado.span()) -> isso pode ser útil para eu quiser o recorte no texto, se precisar!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se eu quiser limpar a fonte:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "substituidos = padrao.sub(r'\\1 \\2 \\3', sentenca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe que agora meus telefones estão limpos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'teste de coisas 0800 942 4425\\n              0900 342 4452\\n              1119 341 4515\\n              3315 331 1049\\n              abcurdas 123 texto'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "substituidos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare com o original:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'teste de coisas 0800 942 4425\\n              0900.342.4452\\n              1119-341-4515\\n              3315 331 1049\\n              abcurdas 123 texto'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentenca"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Outros filtros curiosos\n",
    "\n",
    "Esse é um básico para e-mail:\n",
    "\n",
    "    epasseto@ana.gov.br\n",
    "\n",
    "    padrao = re.compile(r'[a-zA-Z]+@[a-zA-Z]+\\.gov\\.br')\n",
    "    \n",
    "    [a-zA-Z]+@ significa: essa célula tem que ter alfanumérico em caixa alta ou baixa e é repetida várias vezes...          até encontrar uma arroba\n",
    "    \n",
    "    [a-zA-Z]+\\.com significa: vários alfanuméricos mais um ponto (com a barra de escapar de comando) e depois um gov.br\n",
    "    \n",
    "Um mais completo para e-mail:\n",
    "\n",
    "    padrao = re.compile(r'[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+')\n",
    "    \n",
    "*lembrando da seguinte regra: coisas muito justas (como calças muito justas) são difíceis de vestir (e acabam não servindo). Coisas muito folgadas por outro lado, acabam capturando lixo. O que me diz o grau de justeza que eu devo usar? Capture partes do seu dado, faça testes... mas antes de pegar um parser pronto, tente **entender** cada um dos pontos. Se ele estiver folgado demais, ajuste-o. Se estiver apertado demais, afrouxe-o. Há muitas cláusulas para ambas as coisas, vale a pena fazer muitos testes!*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um filtro para endereço Web: \n",
    "\n",
    "*e este vai com os parêntes de agrupamentos, pois não irei usar tudo o que capturei na hora de chamar o endereço!*\n",
    "\n",
    "    https://www.amazon.com\n",
    "    \n",
    "    padrao = re.compile(r'http?://(www\\.)?(/w+\\.)(\\w+)')\n",
    "\n",
    "    http?:// atende a dois padrões: http:// e https:// (o ? significa - tem um caracter a mais aqui?)\n",
    "    \n",
    "    /w representa capturar uma palavra inteira e os pontos separadores levam a \\. para ser pulado o comando .\n",
    "    \n",
    "*lembre que o parser normalmente lida caractere a caractere então aquelas cláusulas enormes entre colchetes dizem respeito no fundo a apenas um caracterzinho... e depois é que eu boto a cláusula de repetição +*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este é um filtro para nomes com pronome de tratamento:\n",
    "\n",
    "    Dr. T\n",
    "    \n",
    "    Sr Mostarda\n",
    "    \n",
    "    Dra Branca\n",
    "\n",
    "    padrao = re.compile(r'(Sr|Sra|Sta|Dr|Dra)\\.?\\s[A-Z]\\w*')\n",
    "    \n",
    "*novamente observe que nem sempre a escrita mais compacta é a melhor: às vezes as coisas precisam poder ser lidas também por humanos! E os testes nos mostraram que este filtro seria bom para os casos acima. Para outros casos, outros filtros (e eu também fico à vontade para simplesmente modificar este aí mesmo!)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Separo doses inicial e final em colunas separadas (depois eliminar os prefixos u ao final de cada dosagem):\n",
    "\n",
    "*simplesmente uso o método **.split()** e depois elimino a coluna original da dosagem com **.drop()** e o problema está resolvido!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "treatments_clean = pd.melt(treatments_clean, id_vars=['given_name', 'surname', 'hba1c_start', 'hba1c_end', 'hba1c_change'],\n",
    "                           var_name='treatment', value_name='dose')\n",
    "treatments_clean = treatments_clean[treatments_clean.dose != \"-\"]\n",
    "treatments_clean['dose_start'], treatments_clean['dose_end'] = treatments_clean['dose'].str.split(' - ', 1).str\n",
    "treatments_clean = treatments_clean.drop('dose', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui eu junto as colunas de nome e sobrenome numa única coluna:\n",
    "\n",
    "*O método **.merge()** faz isso para mim*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "treatments_clean = pd.merge(treatments_clean, adverse_reactions_clean,\n",
    "                            on=['given_name', 'surname'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_names = patients_clean[['patient_id', 'given_name', 'surname']]\n",
    "id_names.given_name = id_names.given_name.str.lower()\n",
    "id_names.surname = id_names.surname.str.lower()\n",
    "treatments_clean = pd.merge(treatments_clean, id_names, on=['given_name', 'surname'])\n",
    "treatments_clean = treatments_clean.drop(['given_name', 'surname'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Patient ID should be the only duplicate column\n",
    "all_columns = pd.Series(list(patients_clean) + list(treatments_clean))\n",
    "all_columns[all_columns.duplicated()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uso do Assert [aqui](https://www.tutorialspoint.com/python/assertions_in_python.htm)\n",
    "\n",
    "---\n",
    "\n",
    "*isso é bom para verificar que fizemos a coisa certa!*\n",
    "\n",
    "palavras em Python [aqui](https://www.programiz.com/python-programming/keyword-list#in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for frase in asap_list:\n",
    "    assert frase not in df_limpo.StartDate.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estratégia cartesiana: dividir o problema em partes menores\n",
    "\n",
    "- **numerador** - uma célula de cálculo\n",
    "\n",
    "- **denominador** - outra célula de cálculo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "\n",
    "df_limpo.StartDate.value_counts().plot(kind=\"pie\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Próximas etapas\n",
    "\n",
    "Para trás:    \n",
    "    \n",
    "    - guardar dados limpos\n",
    "\n",
    "Para frente:\n",
    "    \n",
    "    - analisar\n",
    "    \n",
    "    - visualizar\n",
    "    \n",
    "    - modelizar\n",
    "    \n",
    "---\n",
    "\n",
    "Feature Engineering [aqui](https://en.wikipedia.org/wiki/Feature_engineering)\n",
    "\n",
    "Exploratory Data Analysis - EDA [aqui](https://en.wikipedia.org/wiki/Exploratory_data_analysis)\n",
    "\n",
    "Extract-Transform-Load - ETL (process) [aqui](https://en.wikipedia.org/wiki/Extract,_load,_transform)\n",
    "\n",
    "---\n",
    "\n",
    "ASAP "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arquivos EXCEL [aqui](https://professor-excel.com/xml-zip-excel-file-structure/)\n",
    "\n",
    "Estruturas de Database [aqui](https://www.cac.cornell.edu/education/Training/DataAnalysis/RelationalDatabases.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Beautiful Soup [aqui](https://www.crummy.com/software/BeautifulSoup/bs4/doc/#find)\n",
    "\n",
    "---\n",
    "\n",
    "- unicode [aqui](https://stackoverflow.com/questions/19508442/beautiful-soup-and-unicode-problems)\n",
    "\n",
    "- remover \\xa0 [aqui](https://stackoverflow.com/questions/10993612/python-removing-xa0-from-string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Observe o break no meio do código. Obviamente eu vou criando finds iterativamente e dando um print. À medida que vou elaborando, o resultado fica praticamente perfeito. As últimas instruções simplesmente removem lixo ao final da string, retiram vírgulas, etc.. São comandos comuns do P*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of dictionaries to build file by file and later convert to a DataFrame\n",
    "df_list = []\n",
    "folder = 'rt_html'\n",
    "for movie_html in os.listdir(folder):\n",
    "    with open(os.path.join(folder, movie_html)) as file:\n",
    "        soup = BeautifulSoup(file)\n",
    "        #ao final eu excluo o adicional inútil\n",
    "        title = soup.find('title').contents[0][:-len(' - Rotten Tomatoes')]\n",
    "        \n",
    "        #div é uma lista em texto. No caso, eu pego o primeiro elemento\n",
    "        audience_score = soup.find('div', class_='audience-score meter').find('span').contents[0][:-1]\n",
    "        \n",
    "        #\n",
    "        num_audience_ratings = soup.find('div', class_='audience-info hidden-xs SuperPageFontColor')\n",
    "        num_audience_ratings = num_audience_ratings.find_all('div')[1].contents[2].strip().replace(',','')\n",
    "        #print(title)\n",
    "        #print(audience_score)\n",
    "        #print(num_audience_ratings)\n",
    "        #break\n",
    "        \n",
    "        # Append to list of dictionaries\n",
    "        df_list.append({'title': title,\n",
    "                        'audience_score': int(audience_score),\n",
    "                        'number_of_audience_ratings': int(num_audience_ratings)})\n",
    "df = pd.DataFrame(df_list, columns = ['title', 'audience_score', 'number_of_audience_ratings'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teste da rotina"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_solution = pd.read_pickle('df_solution.pkl')\n",
    "df.sort_values('title', inplace = True)\n",
    "df.reset_index(inplace = True, drop = True)\n",
    "df_solution.sort_values('title', inplace = True)\n",
    "df_solution.reset_index(inplace = True, drop = True)\n",
    "pd.testing.assert_frame_equal(df, df_solution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elementos do HTML [aqui](https://developer.mozilla.org/pt-BR/docs/Web/HTML/Element/span)\n",
    "\n",
    "\n",
    "    <html> (ou HTML root element) representa a raiz\n",
    "    \n",
    "    <span> é um conteiner generico em linha para conteúdo fraseado , que não representa nada por natureza\n",
    "    \n",
    "    <div> é um elemento de nível de bloco enquanto <span> é um elemento em linha\n",
    "    \n",
    "\n",
    "#### Metadados:\n",
    "\n",
    "\n",
    "    <address> informações de contato para seu ancestral <article> ou <body> mais próximo\n",
    "    \n",
    "    <article> uma composição independente em um documento\n",
    "    \n",
    "    <aside> uma seção de uma página que consiste de conteúdo que é tangencialmente relacionado ao conteúdo do seu entorno\n",
    "    \n",
    "    <header> <footer> representa um grupo de suporte introdutório/final ou navegacional\n",
    "    \n",
    "    <h1> .. <h6> são os cabeçalhos\n",
    "    \n",
    "    <hgroup> destina-se a agrupar (conteiner) de cabeçalhos de diferentes níveis para uma seção do documento\n",
    "    \n",
    "    <main> conteúdo principal dentro do <body> em seu documento\n",
    "    \n",
    "    <nav> uma seção de uma página que aponta para outras páginas\n",
    "    \n",
    "    <section> uma seção genérica contida em um documento HTML, geralmente com um título\n",
    "    \n",
    "\n",
    "##### Conteúdo textual:\n",
    "\n",
    "\n",
    "    <blockquote> indica que o texto incluído é uma longa citação\n",
    "    \n",
    "    <dd> inclui os atributos globais como seus\n",
    "    \n",
    "    <dt> termo na lista de definição\n",
    "\n",
    "    <ol> lista de itens ordenados\n",
    "    \n",
    "    <p> parágrafo do texto\n",
    "    \n",
    "    <pre> texto pré-formatado\n",
    "\n",
    "\n",
    "#### Semânticas textuais inline:\n",
    "\n",
    "\n",
    "    <br> quebra de linha\n",
    "\n",
    "    <mark> um trecho de destaque em um texto\n",
    "    \n",
    "    <strong> dá ao texto uma forte importância, tipo negrito\n",
    "    \n",
    "    <time> tempo tanto no formato de 24 horas ou como uma data precisa no calendário Gregoriano\n",
    "    \n",
    "    <var> uma variável em uma expressão matemática ou um contexto de programação\n",
    "    \n",
    "\n",
    "#### Imagem e multimídia:\n",
    "\n",
    "\n",
    "    <img>  (or HTML Image Element) representa a inseração de imagem no documento\n",
    "\n",
    "\n",
    "#### Scripting:\n",
    "\n",
    "\n",
    "    <script> usado para incluir ou referenciar um script executável\n",
    "\n",
    "\n",
    "#### Tabelas:\n",
    "\n",
    "\n",
    "    <table> representa dados em duas dimensões ou mais\n",
    "    \n",
    "    <caption> título de uma tabela\n",
    "    \n",
    "    Embora ele seja sempre o primeiro filho de um <table>, seu estilo, usando CSS pode colocá-lo em qualquer lugar \n",
    "    relativo a tabela\n",
    "\n",
    "    <td> define uma célula de uma tabela que contém os dados. Participa no modelo da tabela\n",
    "    \n",
    "#### Formulários:\n",
    "\n",
    "    <button> representa um botão clicável"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nome_pasta = 'revisoes_ebert'\n",
    "if not os.path.exists(nome_pasta):\n",
    "    os.makedirs(nome_pasta)\n",
    "\n",
    "url = 'http://docs.python-requests.org/en/master/'\n",
    "resposta = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resposta.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(nome_pasta, url.split('/')[-1]), mode='wb'):\n",
    "    file.write(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(nome_pasta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(nome_pasta,\n",
    "                      url.split('/')[-1], mode='wb') as file:\n",
    "          file.write(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "requests URL [aqui](http://docs.python-requests.org/en/master/)\n",
    "\n",
    "documentação URL Lib [aqui](https://docs.python.org/3/howto/urllib2.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mesmo processo, para múltiplos arquivos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ebert_review_urls = ['https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9900_1-the-wizard-of-oz-1939-film/1-the-wizard-of-oz-1939-film.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9901_2-citizen-kane/2-citizen-kane.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9901_3-the-third-man/3-the-third-man.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9902_4-get-out-film/4-get-out-film.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9902_5-mad-max-fury-road/5-mad-max-fury-road.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9902_6-the-cabinet-of-dr.-caligari/6-the-cabinet-of-dr.-caligari.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9903_7-all-about-eve/7-all-about-eve.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9903_8-inside-out-2015-film/8-inside-out-2015-film.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9903_9-the-godfather/9-the-godfather.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9904_10-metropolis-1927-film/10-metropolis-1927-film.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9904_11-e.t.-the-extra-terrestrial/11-e.t.-the-extra-terrestrial.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9904_12-modern-times-film/12-modern-times-film.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9904_14-singin-in-the-rain/14-singin-in-the-rain.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9905_15-boyhood-film/15-boyhood-film.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9905_16-casablanca-film/16-casablanca-film.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9905_17-moonlight-2016-film/17-moonlight-2016-film.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9906_18-psycho-1960-film/18-psycho-1960-film.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9906_19-laura-1944-film/19-laura-1944-film.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9906_20-nosferatu/20-nosferatu.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9907_21-snow-white-and-the-seven-dwarfs-1937-film/21-snow-white-and-the-seven-dwarfs-1937-film.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9907_22-a-hard-day27s-night-film/22-a-hard-day27s-night-film.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9907_23-la-grande-illusion/23-la-grande-illusion.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9908_25-the-battle-of-algiers/25-the-battle-of-algiers.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9908_26-dunkirk-2017-film/26-dunkirk-2017-film.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9908_27-the-maltese-falcon-1941-film/27-the-maltese-falcon-1941-film.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9909_29-12-years-a-slave-film/29-12-years-a-slave-film.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9909_30-gravity-2013-film/30-gravity-2013-film.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9909_31-sunset-boulevard-film/31-sunset-boulevard-film.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad990a_32-king-kong-1933-film/32-king-kong-1933-film.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad990a_33-spotlight-film/33-spotlight-film.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad990a_34-the-adventures-of-robin-hood/34-the-adventures-of-robin-hood.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad990b_35-rashomon/35-rashomon.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad990b_36-rear-window/36-rear-window.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad990b_37-selma-film/37-selma-film.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad990c_38-taxi-driver/38-taxi-driver.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad990c_39-toy-story-3/39-toy-story-3.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad990c_40-argo-2012-film/40-argo-2012-film.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad990d_41-toy-story-2/41-toy-story-2.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad990d_42-the-big-sick/42-the-big-sick.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad990d_43-bride-of-frankenstein/43-bride-of-frankenstein.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad990d_44-zootopia/44-zootopia.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad990e_45-m-1931-film/45-m-1931-film.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad990e_46-wonder-woman-2017-film/46-wonder-woman-2017-film.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad990e_48-alien-film/48-alien-film.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad990f_49-bicycle-thieves/49-bicycle-thieves.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad990f_50-seven-samurai/50-seven-samurai.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad990f_51-the-treasure-of-the-sierra-madre-film/51-the-treasure-of-the-sierra-madre-film.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9910_52-up-2009-film/52-up-2009-film.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9910_53-12-angry-men-1957-film/53-12-angry-men-1957-film.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9910_54-the-400-blows/54-the-400-blows.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9911_55-logan-film/55-logan-film.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9911_57-army-of-shadows/57-army-of-shadows.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9912_58-arrival-film/58-arrival-film.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9912_59-baby-driver/59-baby-driver.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9913_60-a-streetcar-named-desire-1951-film/60-a-streetcar-named-desire-1951-film.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9913_61-the-night-of-the-hunter-film/61-the-night-of-the-hunter-film.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9913_62-star-wars-the-force-awakens/62-star-wars-the-force-awakens.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9913_63-manchester-by-the-sea-film/63-manchester-by-the-sea-film.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9914_64-dr.-strangelove/64-dr.-strangelove.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9914_66-vertigo-film/66-vertigo-film.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9914_67-the-dark-knight-film/67-the-dark-knight-film.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9915_68-touch-of-evil/68-touch-of-evil.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9915_69-the-babadook/69-the-babadook.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9915_72-rosemary27s-baby-film/72-rosemary27s-baby-film.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9916_73-finding-nemo/73-finding-nemo.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9916_74-brooklyn-film/74-brooklyn-film.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9917_75-the-wrestler-2008-film/75-the-wrestler-2008-film.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9917_77-l.a.-confidential-film/77-l.a.-confidential-film.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9918_78-gone-with-the-wind-film/78-gone-with-the-wind-film.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9918_79-the-good-the-bad-and-the-ugly/79-the-good-the-bad-and-the-ugly.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9918_80-skyfall/80-skyfall.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9919_82-tokyo-story/82-tokyo-story.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9919_83-hell-or-high-water-film/83-hell-or-high-water-film.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9919_84-pinocchio-1940-film/84-pinocchio-1940-film.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9919_85-the-jungle-book-2016-film/85-the-jungle-book-2016-film.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad991a_86-la-la-land-film/86-la-la-land-film.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad991b_87-star-trek-film/87-star-trek-film.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad991b_89-apocalypse-now/89-apocalypse-now.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad991c_90-on-the-waterfront/90-on-the-waterfront.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad991c_91-the-wages-of-fear/91-the-wages-of-fear.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad991c_92-the-last-picture-show/92-the-last-picture-show.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad991d_93-harry-potter-and-the-deathly-hallows-part-2/93-harry-potter-and-the-deathly-hallows-part-2.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad991d_94-the-grapes-of-wrath-film/94-the-grapes-of-wrath-film.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad991d_96-man-on-wire/96-man-on-wire.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad991e_97-jaws-film/97-jaws-film.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad991e_98-toy-story/98-toy-story.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad991e_99-the-godfather-part-ii/99-the-godfather-part-ii.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad991e_100-battleship-potemkin/100-battleship-potemkin.txt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make directory if it doesn't already exist\n",
    "folder_name = 'ebert_reviews'\n",
    "if not os.path.exists(folder_name):\n",
    "    os.makedirs(folder_name)\n",
    "    \n",
    "for url in ebert_review_urls:\n",
    "    response = requests.get(url)\n",
    "    with open(os.path.join(folder_name,\n",
    "                      url.split('/')[-1]), mode='wb') as file:\n",
    "          file.write(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import filecmp\n",
    "\n",
    "dc = filecmp.dircmp('ebert_reviews', 'ebert_reviews_solution')\n",
    "assert len(dc.common) == 88"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(folder_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outras maneiras de gravar arquivos binários [aqui](http://docs.python-requests.org/en/latest/user/quickstart/#binary-response-content)\n",
    "\n",
    "O que é WB [aqui](https://stackoverflow.com/questions/2665866/what-does-wb-mean-in-this-code-using-python)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### Codificação texto [aqui](https://www.joelonsoftware.com/2003/10/08/the-absolute-minimum-every-software-developer-absolutely-positively-must-know-about-unicode-and-character-sets-no-excuses/)\n",
    "\n",
    "O que você precisa saber de As platônicos [aqui](https://www.joelonsoftware.com/2003/10/08/the-absolute-minimum-every-software-developer-absolutely-positively-must-know-about-unicode-and-character-sets-no-excuses/)\n",
    "\n",
    "Um aprofundamento [aqui](http://kunststube.net/encoding/)\n",
    "\n",
    "Byte Strings para dar encode e decode [aqui](https://stackoverflow.com/questions/6224052/what-is-the-difference-between-a-string-and-a-byte-string)\n",
    "\n",
    "---\n",
    "\n",
    "Glob para englobar caminhos em árvore [aqui](https://docs.python.org/3/library/glob.html)\n",
    "\n",
    "*usa o que chamam de Wildcard Characters*\n",
    "\n",
    "Diferença entre UTF-8 e UNICODE [aqui](http://www.polylab.dk/utf8-vs-unicode.html)\n",
    "\n",
    "---\n",
    "\n",
    "Criar um dataframe Pandas coluna por coluna a partir de um for [aqui](https://stackoverflow.com/questions/28056171/how-to-build-and-fill-pandas-dataframe-from-for-loop/28058264#28058264)\n",
    "\n",
    "Construtor de dataframe do Pandas [aqui](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "folder_name = 'ebert_reviews'\n",
    "for ebert_review in os.listdir(folder):\n",
    "    with open(os.path.join(folder,\n",
    "        ebert_review)) as file:\n",
    "          file.write(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of dictionaries to build file by file and later convert to a DataFrame\n",
    "df_list = []\n",
    "for ebert_review in glob.glob('ebert_reviews/*.txt'):\n",
    "    with open(ebert_review, encoding='utf-8') as file:\n",
    "        title = file.readline()[:-1]\n",
    "        review_url = file.readline()[:-1]\n",
    "        review_text = file.read() #todo o resto\n",
    "        df_list.append({'title': title,\n",
    "                        'review_url': review_url,\n",
    "                        'review_text': review_text})\n",
    "df = pd.DataFrame(df_list, columns = ['title', 'review_url', 'review_text'])                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_solution = pd.read_pickle('df_solution.pkl')\n",
    "df.sort_values('title', inplace = True)\n",
    "df.reset_index(inplace = True, drop = True)\n",
    "df_solution.sort_values('title', inplace = True)\n",
    "df_solution.reset_index(inplace = True, drop = True)\n",
    "pd.testing.assert_frame_equal(df, df_solution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "- boas práticas em abrir um arquivo em Python [aqui](https://stackoverflow.com/questions/5250744/difference-between-open-and-codecs-open-in-python/22288895#22288895)\n",
    "\n",
    "- maneira Pythônica de abrir um arquivo [aqui](https://stackoverflow.com/questions/8009882/how-to-a-read-large-file-line-by-line-in-python/8010133#8010133)\n",
    "\n",
    "- iteradores na abertura de um arquivo [aqui](https://stackoverflow.com/questions/16994552/is-file-object-in-python-an-iterable/16994568#16994568)\n",
    "\n",
    "- programação Glob [aqui](https://en.wikipedia.org/wiki/Glob_(programming))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### APIs\n",
    "\n",
    "---\n",
    "\n",
    "- como extrair dados de uma delas\n",
    "\n",
    "- diferente de Access Library\n",
    "\n",
    "- preferível a capturar dados de telas!\n",
    "\n",
    "- testes em MediaWiki [aqui](https://www.mediawiki.org/wiki/API:Main_page#A_simple_example)\n",
    "\n",
    "  - endpoints\n",
    "  \n",
    "  - format\n",
    "  \n",
    "  - action\n",
    "  \n",
    "  - action-specific parameters\n",
    "\n",
    "- em Python wptools [aqui](https://www.mediawiki.org/wiki/API:Client_code#Python)\n",
    "\n",
    "- no Twitter tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "$pip install wptools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page = wptools.page('Mahatma_Gandhi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page.data['image']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wptools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page = wptools.page('E.T. Wikipedia page').get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rtsimple as rt\n",
    "rt.API_KEY = ''\n",
    "movie = rt.Movies('10489')\n",
    "movie.ratings['audience_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wptools as wpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wpt.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rtsimple as rt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rt.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Objetos XML/JSON\n",
    "\n",
    "---\n",
    "\n",
    "- Possuem declarações e sempre são fechados em tags e elementos, que podem ter atributos, referências, texto. A sintaxe completa [aqui](https://www.tutorialspoint.com/xml/xml_syntax.htm)\n",
    "\n",
    "- Podem conter estruturas de dados aninhados (uma entrada pode conter mais de um ítem)\n",
    "\n",
    "- Podem ser lidas diretamente por humanos ou por máquinas\n",
    "\n",
    "- Os dois objetos mais consistentes\n",
    "\n",
    "  - JSON object -> Python dictionary\n",
    "  \n",
    "  - JSON array -> Python list\n",
    "\n",
    "- API (Application Programming Interface) data exchange de JSON para XML [aqui](https://www.tibco.com/blog/2014/01/23/api-data-exchange-xml-vs-json/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
